---
title: "Homework4"
author: "KiseokUchicago"
date: "2020-11-01"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.height=4, fig.path='Figs/',
                      error=TRUE, echo=TRUE, eval=TRUE, warning=FALSE, message=FALSE)
```

## Homework4
## Written assignment for Stat 30750
Professor: **Fatma Terzioglu**  
Student: **Kiseok Lee**  

### (2)
(Practical efficiency of LU decomposition) Generate an n x n matrix A with entries drawn independently from the standard normal distribution N(0; 1). Our goal in this exercise is to solve Ax = b for K different b's, where b is an n-vector with entries drawn independently from N(0, 1). Keep track of the computation time for the two methods below.

### (2)-(a)
For n=100, 200, 300, 400, solve Ax=b for x, for K different b, where K = 300, 500.

```{r 'a'}
library(tictoc)
library(dplyr)

# data collecting dataframe
df_time <- data.frame(n =double(), k=double())
df_time

tic.clearlog()
for (n in c(100,200,300,400)){
  print(n)
  A <- matrix(nrow=n, ncol=n)
  for (i in 1:dim(A)[1]){
      A[i,]=rnorm(n)
  }
  dim(A)
  # Create k different b from standard normal distribution N(0,1)
  for (k in c(300,500)){  # k = 300,500
      B <- matrix(nrow=n, ncol=k)
      # I created an matrix containing of all K different b, so that the time of the random sampling is not included the computation time.
      for (j in 1:dim(B)[2]){
          B[,j]=rnorm(n)
      }
      # Solve x for all K different b
      tic()
      for (colm in (1:k)){
        x <- solve(A,B[,colm])
      }
      toc(log=T)
      df_time=rbind(df_time, c(n,k))
    }
}

log.lst <- tic.log(format = FALSE)
tic.clearlog()

timings <- unlist(lapply(log.lst, function(x) x$toc - x$tic))
df_time$comp_time <- timings
colnames(df_time) <- c('n','K','comp_time')
df_time

```

### (2)-(b)
For n = 100; 200; 300; 400, first obtain A = LU. Then For K different b, solve Lc = b for c
followed by solving Ux = c for x. Do so for K = 300; 500.

Due to limit of my computing power, I will use K=3,5. It takes more than 3hr to do for K=300, 500, according to my estimation.

```{r 'b'}
# install.packages('matrixcalc')
library(matrixcalc)

# data collecting dataframe
df_time2 <- data.frame(n =double(), k=double())
df_time2

tic.clearlog()
for (n in c(100,200,300,400)){
  print(n)
  A <- matrix(nrow=n, ncol=n)
  for (i in 1:dim(A)[1]){
      A[i,]=rnorm(n)
  }
  dim(A)
  # Create k different b from standard normal distribution N(0,1)
  for (k in c(3,5)){  # k = 300,500
      B <- matrix(nrow=n, ncol=k)
      # I created an matrix containing of all K different b, so that the time of the random sampling is not included the computation time.
      for (j in 1:dim(B)[2]){
          B[,j]=rnorm(n)
      }
      # Solve x for all K different b
      tic()
      for (colm in (1:k)){
        luA <- lu.decomposition( A )
        L <- luA$L
        U <- luA$U
        c <- solve(L,B[,colm])
        x <- solve(U,c)
      }
      toc(log=T)
      df_time2=rbind(df_time2, c(n,k))
    }
}

log.lst <- tic.log(format = FALSE)
tic.clearlog()

timings <- unlist(lapply(log.lst, function(x) x$toc - x$tic))
df_time2$comp_time <- timings
colnames(df_time2) <- c('n','K','comp_time')
df_time2

# estimate K=300, 500 by multiplying by 100 to the time K=3, K=5
df_time2$K <- df_time2$K * 100
df_time2$comp_time <- df_time$comp_time * 100
df_time2

```

### (2)-(c)
Plot the computation times as a line graph for each K, with n as the horizontal axis, computa
tion time (or log of computation time) as the vertical axis. Plot the two line graphs of K = 300 and 500 on the same plot. Compare and comment.


```{r 'c'}
library(ggplot2)
theme_set(theme_bw())

# merge 2 dataframe of df_time and df_time2
df_time$K <- paste0('Ax=b_',df_time$K)
df_time2$K <- paste0('LUx=b_',df_time2$K)
df_time3 <- bind_rows(df_time, df_time2)

# plot for Ax=b method
df_time3$K <- factor(df_time3$K)
p1 <- ggplot(df_time3,aes(x = n,y = log(comp_time))) +
  geom_line(aes(color=K)) +
  scale_color_brewer(palette='Set2') +
  scale_y_continuous(breaks=seq(-3,8,1))+
  xlab("\n Dimension of matrix(n)") +
  ylab("Computational time\n (log (seconds)) ") +
  ggtitle("Ax=b vs LUx=b method")+
  ## adjust positions
  theme(plot.title = element_text(size = 20,hjust = 0.5, family="serif")) + 
  theme(axis.title.x = element_text(size = 15,hjust = 0.5, family="serif")) + 
  theme(axis.title.y = element_text(size = 15,hjust = 0.5, family="serif")) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust=0.3,size=11))+
  theme(axis.text.y = element_text(size=10))+
  theme(panel.grid.major = element_blank()) +
  theme(panel.grid.minor = element_blank())
p1

```
When you compare the method (a) Ax=b and (b) LUx=b, we can see from the graph that Ax=b method is more than 10,000~100,000 times faster than LU factorization method in all n(100, 200, 300, 400). Therefore, LU decomposition method is practically inefficient compared to the basic method solve() in R. However, there is a possibility that solve() method might be using a more efficient factorization or decomposition method than LU factorization. Also method (b) needs to solve two equations: Lc=b and Ux=c, which could have contributed to longer length of time. K=300 and K=500 does not differ much (less than 10x) in the computational time.



